---
title: "Bootstrapping"
subtitle: '"pulling oneself up by oneâ€™s bootstraps"'
author: "Qicheng Zhao, Kent Lu, Nam-Anh Tran"
format: 
  revealjs:
    theme: league
    transition: fade
editor: source
fontsize: 19.5pt
execute: 
  echo: false
editor_options: 
  chunk_output_type: console
params:
  Bboot: 1000
  ss: 50
bibliography: references.bib
---

## Bootstrap for Linear Regression \| Paired Bootstrap

Assume the following linear regression model, $Y=X\beta+\varepsilon$,
where $Y$ is the response variable, $X$ is the corresponding covariate and $\varepsilon$ is the residuals. 

Uniformly generate news sets of observations from orginal sample $(X_1,Y_1),\dots,(X_n,Y_n)$ with replacement,


$$
(X_1^*,Y_1^*),\dots,(X_n^*,Y_n^*).
$$

Repeat the process $B$ times, we would have totally $B$ bootstrap samples. Using each bootstrap sample to fit one linear regression model, this leads to 

$$
(\widehat{\beta_1^*},\dots,\widehat{\beta_n^*}),
$$
where $\widehat{\beta_i^*}$ is the estimated coefficients using $i$th bootstrap sample, $\forall i = 1,\dots,n$.        

Then we can estimate the confidence interval for $\beta$ (@efron1994introduction).


## Bootstrap for Linear Regression \| Residual Bootstrap

Although paired bootstrap works well in theory, it can lead to a bad estimation when there are outliers in the datasets. To resolve this problem, residual bootstrap is introduced.   

Firstly, generate $e_i$ from the original sample $(X_1,Y_1),\dots,(X_n,Y_n)$ with


$$
e_i=Y_i-\widehat{Y_i}, \forall i=1,\dots,n.
$$

Next, we generate $\widehat{\varepsilon}_1^*,\dots,\widehat{\varepsilon}_n^*$

$$
P(\widehat{\varepsilon}_j^* = e_i)={1\over n}, \forall j =1,\dots,n, \forall i =1,\dots,n 
$$

Then, we generate a new bootstrap sample $(X_1^*,Y_1^*),\dots,(X_n^*,Y_n^*)$ via

$$
X_j^*=X_i, Y_j^*=\widehat{Y_i}+\widehat{\varepsilon}_j^*,\forall j =1,\dots,n, \forall i =1,\dots,n.
$$

Repeat the process $B$ times, and construction of Confidence interval would be the same as Paired bootstrap (@efron1994introduction).

## Bootstrap for Linear Regression \| Wild Bootstrap {.scrollable}

Residual bootstrap does not work well when homoscedastic does not hold in our model, which means $\text{Var}(\varepsilon_i|X_i)$ depends on $X_i$. When implement residual bootstrap, it swaps the residuals regardless of the value of $X_i$. To resolve this problem, wild bootstrap is introduced.

Firstly, generate $e_i$ from the original sample $(X_1,Y_1),\dots,(X_n,Y_n)$ with

$$
e_i=Y_i-\widehat{Y_i}, \forall i=1,\dots,n.
$$

Next, we generate $\widehat{\varepsilon}_1^*,\dots,\widehat{\varepsilon}_n^*$

$$
P(\widehat{\varepsilon}_j^* = e_i)={1\over n}, \forall j =1,\dots,n, \forall i =1,\dots,n 
$$

Then, we generate a new bootstrap sample $(X_1^*,Y_1^*),\dots,(X_n^*,Y_n^*)$ via

$$
X_j^*=X_i, Y_j^*=\widehat{Y_i}+V_j \times \widehat{\varepsilon}_j^*,\forall j =1,\dots,n, \forall i =1,\dots,n,
$$
where $V_j \sim N(0,1)$ (note that $V_j$ can follow non-Gaussian distribution).


Repeat the process $B$ times, and construction of Confidence interval would be the same as Paired bootstrap(@davidson2008wild).

## Simulation

For simulation, we generate a dataset $D_1$ with size of 50 with

$$
Y=\beta_0+X\beta_1+\varepsilon,
$$

where we only consider one covariate in this non-intercept model, and $X \sim N(0,1)$, $\beta=5$, $\varepsilon \sim N(0,1)$.

The dataset $D_1$ will be used for paired bootsrtap and residual bootstrap. 

In order to include heteroskedasticity, we generate a dataset $D_2$ with size of 50 with

$$
Y=\beta_0+X\beta_1+X\varepsilon,
$$

where we only consider one covariate in this non-intercept model, and $X \sim N(0,1)$, $\beta=5$, $\varepsilon \sim N(0,1)$.

- The dataset $D_2$ will be used for wild bootstrap.

- The number of bootstrap sample will be set to 10,000.


## Simulation

<!-- | Bootstrap Method  | Confidence Interval  | -->
<!-- |--------|--------| -->
<!-- | Paired Bootstrap  | (4.94,5.39)   | -->
<!-- | Residual Bootstrap   | (4.92,5.38)   | -->
<!-- | Wild Bootstrap| (4.65,5.42)  | -->
<!-- | Benchmark(Paired Bootstrap, Residual Bootstrap)| (4.90,5.38)| -->
<!-- | Benchmark(Wild Bootstrap)| (4.81,5.26)| -->

<!-- : 95% Confidence Interval for $\beta$ -->

We obtained 95% confidence interval for $\beta$ in simple linear regression model as the benchmark to compare with the result in paired bootstrap, residual bootstrap, and wild bootstrap.


```{r, echo=FALSE}
library(lmboot)

set.seed(260895619)
X<-matrix(rnorm(100),nrow=50,ncol=2)
beta<-c(1,5)
eps<-matrix(rnorm(50),nrow=50,ncol=1)
Y<-X%*%beta+eps
Y_1<-X%*%beta+X[,2]*eps
data<-data.frame(Y=Y,X=X)
data_wild<-data.frame(Y=Y_1,X=X)
##Paired Bootstrap
PairObj <- paired.boot(Y~X, B=10000, seed=260895619)
## 95% CI
pair_ci<-quantile(PairObj$bootEstParam[,3], probs=c(.025, .975))

##Residual Bootstrap
ResidObj <- residual.boot(Y~X, B=10000, seed=260895619) 

## 95% CI

residual_ci<- quantile(ResidObj$bootEstParam[,3], probs=c(.025, .975))

##Wild Bootstrap
WildObj <- wild.boot(Y_1~X, B=100, seed=260895619) #perform the wild bootstrap
wild_ci<- quantile(WildObj$bootEstParam[,3], probs=c(.025, .975))


##
lm_model<-lm(Y~X)
ben1<- confint(lm_model)[3,]


##
lm_model_wild<-lm(Y_1~X)
ben2<- confint(lm_model_wild)[3,]

ci<- cbind(pair_ci, residual_ci,ben1,  wild_ci, ben2  )|> t()


dplyr::tibble(`Bootstrap method` = c("Paired Bootstrap", "Residual Bootstrap","Benchmark", "Wild Bootstrap", "Benchmark"),
              Lower = ci[,1], Upper = ci[,2]
              )|>
  dplyr::mutate(`Length of CI` = Upper - Lower)|>
  dplyr::mutate_if(is.numeric, \(i) round(i,2))|>
  knitr::kable()
```

